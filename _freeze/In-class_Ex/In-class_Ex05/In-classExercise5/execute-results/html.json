{
  "hash": "0f8006c526b30160bf1e92a808b73bce",
  "result": {
    "engine": "knitr",
    "markdown": "---\nformat: \n  html:\n    theme: lux\n    number-sections: true\n\ntitle: \"In-class Exercise 5\"\nauthor: \"Tai Yu Ying\"\ndate: \"Sep 23 2024\"\ndate-modified: \"last-modified\"\nexecute: \n  eval: true\n  echo: true\n  message: false\n  freeze: true\n---\n\n\n\n\n## Setting the Analytical Tools\n\nBefore we get started, we need to ensure that **spdep**, **sf**, **tmap** and **tidyverse** packages of R are currently installed in your R.\n\n-   sf is use for importing and handling geospatial data in R,\n\n-   tidyverse is mainly use for wrangling attribute data in R,\n\n-   spdep will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\n\n-   tmap will be used to prepare cartographic quality chropleth map.\n\nThe code chunk below is used to perform the following tasks:\n\n-   creating a package list containing the necessary R packages,\n\n-   checking if the R packages in the package list have been installed in R,\n\n    -   if they have yet to be installed, RStudio will installed the missing packages,\n\n-   launching the packages into R environment.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, sfdep, tmap, tidyverse)\n```\n:::\n\n\n\n\n## Getting the Data Into R Environment\n\nIn this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv fomat.\n\n### Import shapefile into r environment\n\nThe code chunk below uses [`st_read()`](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import Hunan shapefile into R. The imported shapefile will be **simple features** Object of **sf**.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan <- st_read(dsn = \"Data/geospatial\", \n                 layer = \"Hunan\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Hunan' from data source \n  `C:\\gniyuy\\ISSS626_GA\\In-class_Ex\\In-class_Ex05\\Data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n:::\n\n\n\n\n### Import csv file into r environment\n\nNext, we will import *Hunan_2012.csv* into R by using [`read_csv()`](https://readr.tidyverse.org/reference/read_delim.html) of **readr** package. The output is R data frame class.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan2012 <- read_csv(\"Data/aspatial/Hunan_2012.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n\n\n### Performing relational join\n\nThe code chunk below will be used to update the attribute table of *hunan*’s SpatialPolygonsDataFrame with the attribute fields of *hunan2012* dataframe. This is performed by using [`left_join()`](https://dplyr.tidyverse.org/reference/mutate-joins.html) of **dplyr** package.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_GDPPC <- left_join(hunan, hunan2012) %>%\n  select(1:4, 7, 15)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(County)`\n```\n\n\n:::\n:::\n\n\n\n\n## Plotting a choropleth map\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\ntmap mode set to plotting\n```\n\n\n:::\n\n```{.r .cell-code}\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by county, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n```\n\n::: {.cell-output-display}\n![](In-classExercise5_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\n## Global Measures of Spatial Association\n\n### Step 1: Deriving Queen’s contiguity weights: sfdep methods\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1) \n```\n:::\n\n\n\n\n## Computing Global Moran'I\n\nIn the code chunk below, global moran) function is used to compute the Moran's value. Different from spdep package, the output is a tibble data.frame.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmoranI <- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n```\n\n\n:::\n:::\n\n\n\n\n## Performing Global Moran'sl test\n\nIn general, Moran's I test will be performed instead of just computing the Moran's statistics. With sfdep package, Moran's I test can be performed by using global\\_ shown in the code chunk below.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_moran_test(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMoran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n```\n\n\n:::\n:::\n\n\n\n\n## Performing Global Moran'I permutation test\n\nIn practice, Monte carlo simulation should be used to perform the statistical test. For sfdep, it is supported by *global moran perm()*.\n\nNext, *global_moran_perm()* is used to perform Monte Carlo simulation.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMonte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n\n\n\n## Computing local Moran's I\n\nIn this section, you will learn how to compute Local Moran's I of GDPC at county level by using *local moran ()* of sfdep package.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa <- wm_q %>%\n  mutate(local_moran = local_moran(\n        GDPPC, nb, wt, nsim = 99),\n            .before = 1) %>%\n      unnest(local_moran)\n```\n:::\n",
    "supporting": [
      "In-classExercise5_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}